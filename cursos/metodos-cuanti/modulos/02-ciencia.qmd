---
title: "Introducción al Conocimiento Científico y la Metodología Cuantitativa"
format: html
---

# Introducción  

Al iniciar cualquier recorrido en torno a la investigación científica conviene detenernos a reflexionar sobre lo que entendemos por “ciencia”. Con frecuencia utilizamos la palabra como si fuera un concepto obvio y compartido, pero en realidad se trata de una empresa humana en permanente transformación, atravesada por tensiones internas y debates filosóficos. A lo largo de la historia, distintas disciplinas han reclamado para sí el estatus de *científicas*, y en ese reclamo han discutido qué criterios legitiman su conocimiento, qué métodos se consideran válidos y qué objetivos debe perseguir la investigación[^chalmers1999].  

En el lenguaje común solemos asociar ciencia con objetividad, precisión, neutralidad o incluso con verdad. Sin embargo, esos ideales no se cumplen de manera literal: más bien constituyen **mitos** sobre la naturaleza de lo científico. La ciencia, más que un conjunto de certezas, es un proceso de búsqueda y corrección constante. No promete verdades absolutas, pero sí ofrece un camino compartido para acercarnos a ellas, sometiendo cada hallazgo al escrutinio crítico de la comunidad científica.  

La ciencia es también una actividad social. Los experimentos, los artículos y los datos no circulan en el vacío: dependen de redes de investigadores que debaten, acuerdan o rechazan resultados. Lo que da solidez al conocimiento científico no es una “prueba definitiva” en sentido matemático, sino el **consenso** que se forma en torno a evidencias suficientemente robustas. Ese consenso, a su vez, está atravesado por intereses, disputas y contextos históricos.  

Por ello, cuando hablamos de metodología cuantitativa en ciencias sociales no nos referimos solo a técnicas estadísticas o gráficas. Nos referimos a un entramado amplio que incluye debates epistemológicos sobre qué constituye evidencia válida, qué significa explicar o predecir, y cómo se relaciona el conocimiento científico con la vida social y política. En este módulo no pretendemos agotar el debate —para eso están autores como Popper, Kuhn o Lakatos[^referencias02]— sino **retomar sus bases conceptuales** para entender que aprender metodología es tanto adquirir herramientas como reflexionar sobre sus cimientos filosóficos y sociales.  

# Ciencia como práctica social: mitos y limitaciones  

Al acercarnos a la idea de ciencia solemos cargar una serie de imágenes heredadas del sentido común y la cultura popular. Se imagina al científico como un observador neutral, que aplica un método exacto y libre de valores para obtener conclusiones indiscutibles. La ciencia aparece como un territorio de certezas y pruebas definitivas a veces utilizada como calificativo para elevar argumentos en un debate.

Sin embargo, esta visión es engañosa. La práctica científica real es más compleja y profundamente humana. Como toda empresa social, está atravesada por intereses, decisiones y disputas. Reconocer esta dimensión no niega la validez de la ciencia, sino que permite comprender mejor su funcionamiento. La ciencia nunca ofrece pruebas en sentido lógico-matemático, sino consensos construidos colectivamente y siempre sujetos a revisión[^oreskes2004].  

Incluso el dato más aparentemente “objetivo” es producto de elecciones previas: qué medir, cómo hacerlo y en qué contexto. Detrás de cada número, tabla o gráfico hay una cadena de decisiones que tomaron personas concretas con marcos conceptuales, recursos limitados y en situaciones históricas determinadas. Esa conciencia nos ayuda a desmontar algunos **mitos frecuentes sobre la ciencia** y a comprender que, lejos de debilitarla, reconocer sus límites la hace más sólida.  


## **La objetividad absoluta**  

El mito de la objetividad absoluta presenta a la ciencia como un espejo fiel de la realidad, inmune a los valores o creencias de quienes investigan. Pero lo cierto es que ninguna investigación es completamente ajena a los contextos culturales y políticos donde se produce.  

Por ejemplo, cuando un politólogo decide estudiar la corrupción en América Latina, ya está tomando una decisión cargada de valor: podría haber investigado multiples cuestiones como la cooperación internacional, los partidos políticos o la seguridad ciudadana, pero escogió corrupción como una problematica. Esa selección no invalida su trabajo, pero nos recuerda que la ciencia no nace en el vacío. La objetividad se construye mediante reglas de transparencia (explicar cómo se recolectaron los datos, bajo qué supuestos) y de revisión (permitir que otros colegas evalúen y repliquen los hallazgos).  

En este sentido, la objetividad no es un punto de partida garantizado, sino un resultado frágil que se alcanza colectivamente.  

## **La exactitud infalible**  

Otro mito común es pensar que los datos científicos son siempre precisos y definitivos. En realidad, los datos son aproximaciones a fenómenos complejos.  

Tomemos el caso de las encuestas electorales. Una encuesta puede estimar con bastante confianza el apoyo a un candidato, pero siempre dentro de un margen de error. Si un sondeo muestra que un partido tiene 35% de apoyo, el resultado real puede estar entre 33% y 37%. Aun así, los medios y los ciudadanos suelen leer el 35% como una cifra “exacta”.  

Este mito también aparece en la economía. El Producto Bruto Interno (PBI) de un país se calcula mediante múltiples supuestos sobre producción, precios y consumo. Aunque se expresa como un número con decimales, no deja de ser una construcción estadística sujeta a revisiones posteriores.  

La lección es clara: los datos iluminan la realidad, pero no la capturan por completo.  

## **La neutralidad valorativa**  

Max Weber, uno de los padres de la sociología, advertía que los científicos sociales deben aspirar a la “neutralidad valorativa”. Sin embargo, esto no significa que puedan desprenderse por completo de sus valores.  

Un ejemplo clásico lo encontramos en la investigación sobre políticas de bienestar. Un investigador que parte de un enfoque liberal tenderá a ver los subsidios estatales como distorsiones del mercado. Otro, con una visión más igualitarista, puede interpretarlos como mecanismos de justicia social. Ambos trabajan con datos, pero el marco teórico y los valores influyen en qué consideran relevante y cómo interpretan los resultados.  

Reconocer este sesgo no significa abandonar la aspiración de imparcialidad, sino ser conscientes de que todo conocimiento se elabora dentro de un horizonte cultural e ideológico.  

## **La hipótesis como requisito universal**  

En la enseñanza de la investigación se suele insistir en que todo trabajo debe comenzar con una hipótesis. Aunque las hipótesis son fundamentales en la investigación explicativa, no todas las ciencias avanzan de esa manera.  

Un ejemplo lo encontramos en los estudios descriptivos. Supongamos que un investigador crea una base de datos de todos los tratados internacionales firmados por países de América Latina desde 1900. Puede que no formule una hipótesis inicial, sino que su aporte consista en ordenar información que antes estaba dispersa. Esa descripción es valiosa porque permitirá a futuros investigadores plantear hipótesis más sofisticadas sobre patrones de cooperación o conflicto.  

En este sentido, no toda ciencia necesita comenzar con una predicción: también puede iniciar con una tarea paciente de descripción y clasificación.  

## **La causalidad definitiva**  

Quizás el mito más difícil de desmontar es el de la causalidad definitiva. En las ciencias naturales estamos acostumbrados a leyes como la de la gravedad, que se cumplen de manera determinista: bajo las mismas condiciones, el resultado será siempre el mismo.  

En cambio, en ciencias sociales trabajamos con relaciones probabilísticas. Por ejemplo, sabemos que un alto desempleo **aumenta la probabilidad** de que un gobierno pierda una elección, pero no determina de manera absoluta ese resultado. Hay gobiernos que sobreviven con altos niveles de desempleo, y otros que caen incluso con buenos indicadores económicos.  

Este carácter probabilístico se ve en fenómenos internacionales. La existencia de disputas territoriales incrementa la probabilidad de conflictos bélicos, pero no todos los litigios fronterizos terminan en guerra. La causalidad, en ciencias sociales, es siempre condicional y contextual.  

## Una lección para el investigador social  

Aceptar estas limitaciones no debilita la ciencia, sino que la fortalece. Nos obliga a trabajar con **humildad intelectual**, sabiendo que nuestras conclusiones son siempre provisorias. También nos recuerda que el conocimiento es un **esfuerzo colectivo**: ningún investigador por sí solo produce verdades absolutas, sino aportes que se ponen a prueba y se corrigen en diálogo con la comunidad.  

El estudiante que se inicia en la investigación debe tener presente esta doble dimensión: la necesidad de aplicar técnicas rigurosas, pero también la conciencia crítica de que ningún dato ni método agotan por completo la complejidad de lo social.  


# ¿Para qué ciencia? Entre la descripción, la explicación y la predicción  

Una de las funciones centrales de la ciencia suele ser presentada como la capacidad de **explicar** por qué ocurren los fenómenos y, en ciertos casos, de **predecir** lo que ocurrirá. Esta visión tiene mucho de cierto: gran parte de la historia de la ciencia puede narrarse como el esfuerzo por encontrar causas, mecanismos y regularidades que nos permitan anticipar el futuro.  

Sin embargo, como vimos previamente detenernos únicamente en ese horizonte explicativo y predictivo corre el riesgo de subestimar otra dimensión igualmente fundamental: la **descripción sistemática**. Antes de que podamos explicar o predecir algo, necesitamos saber **qué es lo que ocurre** y cómo se manifiesta.

En las ciencias sociales, la descripción no es un ejercicio pasivo, sino una tarea activa de construcción de conocimiento. Crear una base de datos con todas las transiciones democráticas en América Latina, elaborar un mapa de la distribución de bases militares en el mundo o clasificar los tipos de regímenes autoritarios son tareas descriptivas que abren el camino a explicaciones futuras. Sin esos registros básicos, no habría terreno sobre el cual construir modelos explicativos más ambiciosos.  

Por ejemplo, el Índice de Desarrollo Humano (IDH) elaborado por Naciones Unidas no predice directamente el destino de un país, pero su función descriptiva ha sido decisiva para orientar debates sobre desigualdad, políticas públicas y cooperación internacional. 

En este sentido, el **horizonte de la ciencia** suele ser explicar y predecir, aun cuando valoramos el papel de la descripción como **punto de partida indispensable**. Sin embargo, explicación y predicción no siempre se buscan al mismo tiempo ni en la misma medida. En física, por ejemplo, la predicción ocupa un lugar central; en biologia, en cambio, suele predominar la explicación, mientras que en medicina, ambas se persiguen en distinta medida dependiendo de la rama.  

En ciencias sociales coexisten ambas aspiraciones. A veces nos interesa **explicar** cómo se produce un fenómeno —por ejemplo, qué condiciones llevaron a la transición democrática en un país— y otras veces nos interesa **predecir** —como cuando construimos modelos para anticipar resultados electorales. Al mismo tiempo, repetimos, la ciencia no avanza en el vacío: los modelos teóricos guían nuestras preguntas y muchas veces se sostienen incluso sin verificación constante, porque funcionan como capas tectónicas que orientan la investigación [^oreskes2004] .  

> “Los modelos teóricos pueden no ser literalmente verdaderos, pero orientan la investigación y estructuran las expectativas. En muchos campos, se mantienen por su capacidad de organizar el conocimiento, aun cuando no sean verificados constantemente.”  
> *(Oreskes, 2004)*

## Determinismo, probabilismo y el papel de los contrafácticos  

Las ciencias naturales han forjado su prestigio sobre leyes de carácter **determinista**: si dejamos caer un objeto bajo condiciones controladas, siempre se comportará igual. En cambio, las ciencias sociales rara vez ofrecen ese nivel de certeza. Nuestros hallazgos se formulan en términos **probabilísticos**: afirmamos que ciertas condiciones *aumentan* o *disminuyen* la probabilidad de que algo ocurra, pero sin garantizar resultados idénticos en todos los casos.  

Un ejemplo claro es el de las crisis económicas y la estabilidad política. Sabemos que las recesiones tienden a erosionar el apoyo a los gobiernos, pero no todas las recesiones generan caídas de presidentes ni todas las bonanzas aseguran estabilidad. Lo que encontramos son patrones, no certezas inmutables.  

Este carácter probabilístico nos lleva al problema de los **contrafácticos**: para demostrar que un evento causa otro deberíamos poder observar qué habría ocurrido en un mundo paralelo donde la causa no existió. ¿Habría estallado la Primera Guerra Mundial si no hubiera ocurrido el asesinato del archiduque Francisco Fernando? Como nunca podremos observar ese mundo alternativo, recurrimos a aproximaciones indirectas: comparar casos similares, diseñar modelos estadísticos o aprovechar “experimentos naturales” donde ciertas condiciones se dieron sin intervención del investigador[^morgan2014].  

La imposibilidad de manipular fenómenos como guerras, transiciones de régimen o crisis financieras hace que en ciencias sociales dependamos fuertemente de la **evidencia observacional** y de técnicas estadísticas que buscan acercarnos a ese escenario contrafáctico imposible. Además, hay un límite ético evidente: sería impensable “provocar” una guerra para poner a prueba una teoría de relaciones internacionales.  

En este marco, la investigación social se enfrenta a un doble desafío: reconocer que no alcanzará la exactitud de las leyes físicas, pero también valorar que sus descripciones, explicaciones y predicciones aportan insumos fundamentales para comprender —y en muchos casos mejorar— la vida política y social.  
 


# Metodología, métodos y técnicas: dos tradiciones en diálogo  

Cuando nos adentramos en el mundo de la investigación social es fácil confundir términos que parecen sinónimos pero que en realidad refieren a niveles distintos de la práctica científica. Ubicar cada concepto en su nivel correcto evita malentendidos y, sobre todo, nos ayuda a organizar con claridad nuestro propio trabajo de investigación.  

En primer lugar, la **metodología** se sitúa en el plano más abstracto y reflexivo. Es la disciplina que se pregunta por la validez de los métodos, sus supuestos epistemológicos y sus límites. Cuando un investigador discute si un experimento social puede considerarse éticamente válido, o si una encuesta realmente capta la opinión pública que pretende medir, está trabajando en un plano metodológico. La metodología, en este sentido, no aplica herramientas sino que piensa críticamente sobre su pertinencia y alcance.  

El **método**, en cambio, es un nivel más concreto. Se refiere al camino general elegido para producir conocimiento: el método comparativo, el experimental, el histórico o el hipotético-deductivo. Cada uno implica supuestos distintos sobre cómo conocer la realidad y orienta las preguntas que podemos hacernos. Por ejemplo, el método comparativo permite analizar semejanzas y diferencias entre países mientras que el experimental busca aislar variables en condiciones controladas.

Finalmente, la **técnica** ocupa el plano más operativo. Son los instrumentos concretos que usamos para recolectar o analizar información: aplicar cuestionarios, realizar entrevistas, construir bases de datos, calcular coeficientes estadísticos. Las técnicas se aprenden y perfeccionan con la práctica, pero nunca son neutrales, adquieren sentido en la medida en que se insertan en un método y, a su vez, en una reflexión metodológica más amplia.  

Confundir estos tres niveles puede llevar a errores importantes. Creer que basta con aplicar una técnica para obtener “resultados científicos” es una ilusión peligrosa. Una encuesta mal diseñada no se vuelve válida solo por tener números, del mismo modo que un experimento improvisado no se transforma en ciencia por incluir un grupo de control. La coherencia entre metodología, método y técnica es lo que da solidez al conocimiento.  

## Dos tradiciones en ciencias sociales: lo cuantitativo y lo cualitativo  

Dentro de este marco aparecen las dos grandes tradiciones de investigación en ciencias sociales, la **cuantitativa** y la **cualitativa**.  

El enfoque **cuantitativo**, fuertemente influenciado por el positivismo, privilegia la medición y la búsqueda de patrones generales. Su fuerza radica en la estandarización: aplicar las mismas preguntas en encuestas masivas, comparar series estadísticas de largo plazo, construir modelos que permiten detectar regularidades y, en algunos casos, realizar predicciones. Gracias a este enfoque sabemos, por ejemplo, cómo la inflación incide en el voto en distintos países o qué factores suelen estar asociados a las transiciones democráticas.
>nota, citar articulos de ejemplo.

El enfoque **cualitativo**, en cambio, pone el acento en la comprensión profunda de fenómenos singulares. Inspirado en tradiciones como la fenomenología o el interaccionismo simbólico, se interesa por los significados, las experiencias y las narrativas. Una entrevista en profundidad con líderes sociales, el análisis de discursos políticos o la reconstrucción de un proceso histórico específico son ejemplos de técnicas cualitativas. Aunque sus hallazgos no siempre son generalizables, aportan una riqueza interpretativa difícil de alcanzar mediante la cuantificación.  

Ninguno de estos enfoques es “mejor” en términos absolutos. Cada uno responde a distintos tipos de preguntas. Si buscamos explicar **patrones estructurales** —como las causas recurrentes de guerras o las dinámicas de democratización— probablemente necesitemos herramientas cuantitativas. Si en cambio nos interesa entender la **singularidad** de un caso excepcional, como el estallido de la Segunda Guerra Mundial o el rol específico de un líder en un proceso político, el camino será cualitativo.  

Lo central es recordar que la **pregunta de investigación** debe guiar la elección, y no al revés. Elegir un método porque es el que “sabemos usar” o el que “tiene más prestigio” es un error común. La coherencia surge cuando la pregunta, la metodología y las técnicas se alinean. En última instancia, tanto lo cuantitativo como lo cualitativo son complementarios. El verdadero oficio del investigador radica en saber articular estas herramientas, con la reflexión metodológica como brújula.  

## Usando las herramientas de la estadística  

El enfoque cuantitativo que exploraremos en este curso se apoya en la **estadística**, una disciplina con historia, filosofía propia y debates internos sobre sus límites y posibilidades. Así como la filosofía de la ciencia se pregunta qué significa conocer, la estadística reflexiona sobre su objeto de estudio y los supuestos que posibilitan su actividad.  

Comprender esta dimensión es crucial para nuestro curso. Las herramientas estadísticas evolucionaron originalmente en contextos como la biología, la ingeniería o la meteorología, y trasladarlas a fenómenos sociales implica adaptarlas, cuestionar sus supuestos y reconocer sus limitaciones.  

Un caso ilustrativo es el de la **probabilidad**. La escuela estadística más influyente —la frecuentista— entiende la probabilidad como la frecuencia con que ocurre un evento bajo **infinitas repeticiones**. En un ejemplo clásico: ¿cuál es la probabilidad de que llueva mañana? La respuesta se construye pensando en una secuencia interminable de días con las mismas condiciones meteorológicas. De manera similar, los ingenieros calculan la probabilidad de que un bloque de cemento se quiebre bajo pruebas repetidas de resistencia.  

Trasladar este razonamiento a la ciencia política es más complicado. Podemos suponer, por ejemplo, que votantes con características semejantes (edad, educación, nivel socioeconómico, lugar de residencia) tenderán a comportarse de manera similar. Así, como los meteorólogos, intentamos estimar probabilidades de comportamiento electoral. Pero la comparación tiene límites evidentes: mientras que el clima y los materiales responden a leyes físicas relativamente estables, los seres humanos interpretan, reaccionan y cambian sus preferencias de formas menos predecibles.  

El problema se vuelve aún más claro con fenómenos excepcionales. ¿Cuáles son las probabilidades de que ocurra una nueva guerra mundial? Solo tenemos dos casos en la historia, cada uno con circunstancias irrepetibles. Hablar de “infinitas repeticiones” en este contexto es absurdo: no habrá infinitas Alemanias nazis ni infinitos archiduques asesinados en Sarajevo. Aquí la estadística tropieza con la singularidad histórica, y el investigador debe usar su juicio crítico para decidir hasta dónde confiar en los números y hasta dónde tratarlos con cautela.  
En definitiva la estadística es un aliado indispensable, pero nunca puede aplicarse de manera mecánica. Su uso requiere siempre **conciencia metodológica** que ejercitaremos a lo largo del curso, saber qué supuestos sostienen nuestras técnicas, qué preguntas son legítimas responder con ellas y cuáles exigen otras aproximaciones[^blalock].  

# De la ciencia a los científicos: el espacio de trabajo  

Si hasta aquí hemos hablado de la ciencia como empresa abstracta, de la que seremos parte, pero conviene recordar que consumimos todo el tiempo los productos cientificos. Nuestro tiempo en clase, tanto en este curso como en todos los demas que traten temas empiricos, se desarrollan leyendo, estudiando e interpretando, estudios cientificos. Parte de la oficio colectivo de la investigacion es aproximarse a las personas concretas: los investigadores. Y como en cualquier profesión, los científicos trabajan en entornos con reglas, incentivos y tensiones que moldean su práctica.  

En la vida académica, la presión por **publicar** es tan fuerte como en una oficina lo es la presión por cumplir objetivos de ventas o plazos administrativos. Ascensos, becas y financiamiento dependen muchas veces del número de artículos publicados o de la visibilidad que alcanzan. Este sistema, semejante al de burocracias estatales o a las jerarquías militares, genera incentivos que no siempre favorecen la calidad del conocimiento.  

Entre estos incentivos aparecen conductas habituales: dividir un mismo hallazgo en varios artículos para multiplicar publicaciones; citar estratégicamente a colegas para recibir citas de vuelta; o recurrir a estudiantes como asistentes de investigación que potencien la productividad del equipo. Tales prácticas no son necesariamente fraudulentas, forman parte de las “reglas del juego” en muchos espacios académicos y se asumen como parte del desarrollo profesional.  

Sin embargo, también existen **límites éticos**. Normas editoriales prohíben el autoplagio, exigen dar crédito a todos los coautores y sancionan la manipulación deliberada de datos. Aun así, como toda norma social, estas reglas se enfrentan a desafíos de cumplimiento. Uno de los casos más emblemáticos ha sido precisamente el **falsamiento de datos**, investigadores que inventan o modifican resultados para publicar hallazgos “atractivos”.  

Estos episodios ponen de relieve una verdad central: la ciencia no es solo un conjunto de métodos y técnicas, sino también una comunidad de personas con incentivos, valores y dilemas éticos. Comprender ese contexto es tan importante como aprender fórmulas o dominar programas estadísticos. El estudiante que se inicia en la investigación debe saber que su trabajo se inserta en un entramado humano, institucional y social que condiciona qué preguntas se hacen, qué respuestas se consideran legítimas y cómo circula el conocimiento.  


## La revolución de la replicación: un estudio de caso sobre normas y prácticas en la comunidad científica  

En los últimos años, las ciencias sociales —y particularmente la psicología— atravesaron un proceso que muchos llaman la **crisis de replicación**. Todo comenzó cuando varios investigadores intentaron volver a realizar experimentos que habían alcanzado enorme notoriedad y visibilidad académica, solo para descubrir que los resultados no podían repetirse con la misma consistencia. Estudios que habían sido citados miles de veces, utilizados en manuales universitarios y divulgados en medios de comunicación resultaron frágiles cuando se intentó reproducirlos en nuevos contextos.  

Frente a esta situación, la reacción fue construir un nuevo conjunto de normas profesionales que hoy se conocen como **la revolución de la replicación**. Entre las prácticas que se consolidaron destacan:  

- **Pre-registro de hipótesis y métodos.** Antes de recolectar datos, los investigadores deben declarar públicamente cuáles son sus hipótesis, qué variables medirán y cómo planean analizarlas. Esto reduce la tentación de “ajustar” las hipótesis una vez conocidos los resultados (lo que se conoce como *p-hacking*).  

- **Apertura de datos y códigos.** Las revistas y conferencias empezaron a exigir que los datos recolectados y los programas de análisis estuvieran disponibles para otros investigadores. Esto permite verificar resultados, descubrir errores y aprovechar las bases de datos para nuevas investigaciones.  

- **Documentación detallada de procesos.** Ya no basta con presentar tablas o gráficos finales. Los artículos deben incluir información minuciosa sobre cómo se diseñaron los experimentos, cómo se aplicaron encuestas y cómo se procesaron los datos.

Estas medidas no buscan eliminar los errores, sino hacerlos **detectables** y **corregibles**. En otras palabras, institucionalizan la crítica como parte del proceso científico. Ello no implica que todo sea perfecto, ni que los mecanismos sean ineludibles, pero existen normas eticas y un **esfuerzo colectivo**, donde la credibilidad depende de la cooperación y la verificación mutua.

La revolución de la replicación es una gran oportunidad. Compartir datos, reconocer errores y valorar la crítica como parte constitutiva del conocimiento hacen mas facil embarcarse en la investigacion. Grandes debates han comenzado con un estudiante descargando los datos de una investigacion que leyo e intentando mejorarla.
>nota, ver articulos de replicacion publicados y el debate de alianzas entre leeds y kendrick.

# Conclusión: hacia un abordaje crítico y plural  

A lo largo de este modulo hemos visto que la ciencia no es un camino lineal hacia verdades absolutas, sino una práctica social en constante revisión. Reconocer su naturaleza humana, histórica y comunitaria no debilita el conocimiento, sino que lo vuelve más consciente y responsable. En este marco, la **metodología cuantitativa** se nos presenta como un conjunto de herramientas potentes para identificar patrones, comparar casos y establecer inferencias. Sin embargo, estas herramientas solo alcanzan su verdadero valor cuando se usan con **conciencia crítica**, en diálogo con otros enfoques y con una reflexión filosófica sobre qué significa “conocer” en ciencias sociales.  

Es importante también recordar que **no todo conocimiento válido es necesariamente científico** en el sentido estricto. La sabiduría práctica, la filosofía, la experiencia acumulada en comunidades o el saber popular forman parte de otras formas de comprender el mundo que no dependen de métodos estadísticos o de pruebas empíricas. Reconocer esto nos ayuda a evitar dos errores comunes: por un lado, la falacia de apelar a la ciencia como argumento de autoridad incuestionable; por otro, la idea de que lo que no se mide carece de valor. La ciencia debe dialogar con estos otros saberes, no presentarse como el único camino hacia la comprensión.  

Para el investigador social, esta conclusión tiene una implicación central: nuestro rol no consiste únicamente en producir cifras o tablas, sino en contribuir a una **mirada más amplia sobre la realidad política y social**. La cuantificación nos ayuda a ordenar fenómenos y a detectar regularidades, pero nunca reemplaza la complejidad del mundo vivido. El desafío es saber cuándo medir, cuándo interpretar y cuándo escuchar otras voces y tradiciones de pensamiento.  

En suma, lo mensurable no agota lo real. La riqueza del conocimiento científico surge precisamente de su capacidad para **combinar la descripción, la explicación y la predicción**, reconociendo siempre sus límites. Solo así podremos construir una práctica científica plural, abierta y crítica, capaz de orientar nuestras sociedades sin caer en dogmatismos ni en ilusiones de certeza absoluta.  

El estudiante que se inicia en este camino debe llevarse una convicción doble: la ciencia es una de las formas más poderosas de aproximarnos a la realidad, pero no es la única; y su fortaleza radica menos en ofrecer verdades definitivas que en mantener viva la disposición a revisar, debatir y mejorar lo que sabemos.  




::: {.callout-note appearance="simple" icon="false"}

# Seleccionen un trayecto de aprendizaje  

La ciencia política se distingue de prácticas como el arte de gobernar, la estrategia electoral o el marketing político porque busca abordar los fenómenos con herramientas sistemáticas, contrastables y comparables. No obstante, todas esas actividades se nurten de datos e informacion estadistica.

En este curso, además de los fundamentos metodológicos generales, te proponemos **cuatro trayectos de ejercicios prácticos**. Cada uno refleja un perfil profesional distinto y te permitirá entrenarte en un tipo específico de análisis y herramientas. Revisen en los siguientes escenarios y evaluen en cuál te ves más reflejado:  

1. **Académico cuantitativo**  
   - *Escenario:* “Quiero entrar en diálogo con los hallazgos empíricos recientes y aportar, aunque sea en pequeña medida, al debate que me antecede. Me interesa producir evidencia nueva para responder preguntas clásicas: ¿por qué ocurren las guerras? ¿Qué factores explican la democratización?”  
   - *Ejemplo de ejercicio:* construir hipótesis, testearlas con bases de datos internacionales y discutir sus implicaciones teóricas.  

2. **Analista de datos general**  
   - *Escenario:* “Me interesa adquirir herramientas versátiles de análisis de datos, más allá de la ciencia política. Quiero aprender a limpiar, organizar y visualizar información de forma clara para distintos ámbitos profesionales.”  
   - *Ejemplo de ejercicio:* procesar un conjunto de datos socioeconómicos y elaborar visualizaciones para comunicar tendencias de manera sencilla y efectiva.  

3. **Analista de políticas públicas**  
   - *Escenario:* “Quiero orientarme al estudio de problemas sociales concretos y contribuir a mejorar la gestión pública. Me interesa la evaluación de programas, el diseño de indicadores y la formulación de recomendaciones para la toma de decisiones.”  
   - *Ejemplo de ejercicio:* analizar la efectividad de un programa de asistencia social con métodos comparativos y evaluar factores contextuales que incrementan o disminuyen el impacto de la iniciativa.  

4. **Analista de opinión pública**  
   - *Escenario:* “Me atrae más la estrategia política y el estudio de la opinión. Me interesa entender cómo piensan y votan los ciudadanos, interpretar encuestas y comunicar hallazgos a audiencias no especializadas.”  
   - *Ejemplo de ejercicio:* diseñar un cuestionario breve sobre actitudes hacia la distintos candidatos, aplicar una encuesta piloto y analizar los resultados con herramientas básicas de estadística.  

---

En base a estos escenarios, te invitamos a elegir el trayecto que mejor se ajuste a tus intereses. La materia te dará un panorama amplio de las herramientas metodológicas, pero estos perfiles profesionales te orientarán hacia un **camino de aprendizaje específico**, con actividades y competencias alineadas a tu futuro académico o laboral.  
:::


# Material para expandir este modulo

Booth - the craft of research
Ruse - creation science is not science
Curd et al - philosophy of science: the central issues

## Bibliografía

- Blalock, H. M. (1982). *Conceptualization and Measurement in the Social Sciences*.  
- Chalmers, A. (1999). *What Is This Thing Called Science?*  
- Jauretche, A. (1966). *El medio pelo en la sociedad argentina*.  
- Matthews, M. (2009). *Science, Worldviews and Education*.  
- Morgan, S. & Winship, C. (2014). *Counterfactuals and Causal Inference*.  
- Oreskes, N. (2004). *Science and Public Policy: What’s Proof Got to Do with It?*  
- Goertz, G., & Mahoney, J. (2012). *A Tale of Two Cultures: Qualitative and Quantitative Research in the Social Sciences*. 
## Referencias  

[^chalmers1999]: Chalmers, A. F. (1999). *¿Qué es esa cosa llamada ciencia?*  
[^oreskes2004]: Oreskes, N. (2004). “Science and public policy: what’s proof got to do with it?” *Environmental Science & Policy*.  
[^referencias02]: Popper, K. (1935), Kuhn, T. (1962), Lakatos, I. (1978).  
[^morgan2014]: Morgan, S. L., & Winship, C. (2014). *Counterfactuals and Causal Inference*.  
[^blalock]: Blalock, H. M. (1982). *Conceptualization and Measurement in the Social Sciences*.  


>Dada la pretencion practica de este material, hacemos una descipcion mas cercana a la *ciencia normal* de Kuhn, donde el oficio del investigador se encuentra ecausado en una serie de problemas concretos a investigar, asi como la aceptacion de algunas formas de evidencia sobre otras. Ello no implica que la creatividad o el crecimiento sea lineal y progresivo en un sentido de verificabilidad positivista. Si quiere decir que existe una serie de normas profesionales en la practica del dia a dia del investigador empirico. Oreskes ofrece una revision de algunos casos concretos sobre su funcionamiento. Mearshimmer y Walt (2014) ofrecen una critica a este tipo de practicas en su formato mas extremo, el testeo de hipotesis multiples sin discusion teorica que la guie. 